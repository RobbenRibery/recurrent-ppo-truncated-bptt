{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and b\n",
      "tensor([[0.4566, 0.4961, 0.3088, 0.9393],\n",
      "        [0.6863, 0.8910, 0.9775, 0.2971]])\n",
      "tensor([[0.9515, 0.2214, 0.6308, 0.9002],\n",
      "        [0.3194, 0.7220, 0.9200, 0.7176]])\n",
      "c size:\n",
      "torch.Size([2, 8])\n",
      "d\n",
      "tensor([[0.5807, 0.5835, 0.6693, 0.9280, 0.5016, 0.8280, 0.2869, 0.8108],\n",
      "        [0.6894, 0.1667, 0.0125, 0.8738, 0.9797, 0.9346, 0.6939, 0.1501]])\n",
      "e = c + d\n",
      "tensor([[1.0373, 1.0796, 0.9781, 1.8673, 1.4531, 1.0494, 0.9176, 1.7110],\n",
      "        [1.3757, 1.0577, 0.9900, 1.1709, 1.2991, 1.6566, 1.6138, 0.8677]])\n",
      "f = c.to_full_tensor() + d\n",
      "tensor([[1.0373, 1.0796, 0.9781, 1.8673, 1.4531, 1.0494, 0.9176, 1.7110],\n",
      "        [1.3757, 1.0577, 0.9900, 1.1709, 1.2991, 1.6566, 1.6138, 0.8677]])\n",
      "c += d\n",
      "tensor([[1.0373, 1.0796, 0.9781, 1.8673, 1.4531, 1.0494, 0.9176, 1.7110],\n",
      "        [1.3757, 1.0577, 0.9900, 1.1709, 1.2991, 1.6566, 1.6138, 0.8677]])\n",
      "a and b are changed:\n",
      "tensor([[1.0373, 1.0796, 0.9781, 1.8673],\n",
      "        [1.3757, 1.0577, 0.9900, 1.1709]]) tensor([[1.4531, 1.0494, 0.9176, 1.7110],\n",
      "        [1.2991, 1.6566, 1.6138, 0.8677]])\n",
      "g\n",
      "tensor([[0.8181, 0.0790, 0.8816],\n",
      "        [0.6046, 0.3596, 0.4354],\n",
      "        [0.7555, 0.5558, 0.6732],\n",
      "        [0.3492, 0.5181, 0.1957],\n",
      "        [0.5605, 0.6931, 0.6006],\n",
      "        [0.4112, 0.6253, 0.2592],\n",
      "        [0.7740, 0.4236, 0.8760],\n",
      "        [0.3007, 0.3487, 0.0864]])\n",
      "h = c.mm(g)\n",
      "tensor([[5.3630, 4.6300, 4.5047],\n",
      "        [5.8411, 4.5685, 5.2671]])\n",
      "k = c.to_full_tensor().mm(g)\n",
      "tensor([[5.3630, 4.6300, 4.5047],\n",
      "        [5.8411, 4.5685, 5.2671]])\n"
     ]
    }
   ],
   "source": [
    "class MySharedTensor(object):\n",
    "    def __init__(self, tensors, dim=None):\n",
    "        assert dim is not None\n",
    "        self.dim = dim\n",
    "        assert (isinstance(tensors, list))\n",
    "        assert (torch.is_tensor(t) for t in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.dim_sizes = [t.size(self.dim) for t in self.tensors]\n",
    "\n",
    "    # If you want to recover a single Tensor from it\n",
    "    def to_full_tensor(self):\n",
    "        return torch.cat(self.tensors, dim=self.dim)\n",
    "\n",
    "    # Out of place addition\n",
    "    def __add__(self, other):\n",
    "        assert torch.is_tensor(other)\n",
    "        out = other.clone()\n",
    "        curr_idx = 0\n",
    "        for i, t in enumerate(self.tensors):\n",
    "            other_slice = other.narrow(self.dim, curr_idx, self.dim_sizes[i])\n",
    "            out.narrow(self.dim, curr_idx, self.dim_sizes[i]).copy_(t).add_(other_slice)\n",
    "            curr_idx += self.dim_sizes[i]\n",
    "        return out\n",
    "\n",
    "    # Inplace add\n",
    "    def __iadd__(self, other):\n",
    "        assert torch.is_tensor(other)\n",
    "        curr_idx = 0\n",
    "        for i, t in enumerate(self.tensors):\n",
    "            other_slice = other.narrow(self.dim, curr_idx, self.dim_sizes[i])\n",
    "            t.add_(other_slice)\n",
    "            curr_idx += self.dim_sizes[i]\n",
    "        return self\n",
    "\n",
    "    # Matrix Multiplication (only 2d matrices for simplicity)\n",
    "    def mm(self, other):\n",
    "        assert other.ndimension() == 2\n",
    "        assert all(t.ndimension() == 2 for t in self.tensors)\n",
    "\n",
    "        if self.dim == 0:\n",
    "            out_tensors = []\n",
    "            for t in self.tensors:\n",
    "                out_tensors.append(t.mm(other))\n",
    "            return MySharedTensor(out_tensors, dim=0)\n",
    "        elif self.dim == 1:\n",
    "            out = 0\n",
    "            curr_idx = 0\n",
    "            for i, t in enumerate(self.tensors):\n",
    "                other_slice = other.narrow(0, curr_idx, self.dim_sizes[i])\n",
    "                out += t.mm(other_slice)\n",
    "                curr_idx += self.dim_sizes[i]\n",
    "            return out\n",
    "        else:\n",
    "            raise RuntimeError(\"Invalid dimension\")\n",
    "\n",
    "\n",
    "a = torch.rand(2, 4)\n",
    "b = torch.rand(2, 4)\n",
    "print(\"a and b\")\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "c = MySharedTensor([a, b], dim=1)\n",
    "print(\"c size:\")\n",
    "print(c.to_full_tensor().size())\n",
    "\n",
    "d = torch.rand(2, 8)\n",
    "print(\"d\")\n",
    "print(d)\n",
    "\n",
    "e = c + d\n",
    "print(\"e = c + d\")\n",
    "print(e)\n",
    "\n",
    "f = c.to_full_tensor() + d\n",
    "print(\"f = c.to_full_tensor() + d\")\n",
    "print(f)\n",
    "\n",
    "c += d\n",
    "print(\"c += d\")\n",
    "print(c.to_full_tensor())\n",
    "print(\"a and b are changed:\")\n",
    "print(a, b)\n",
    "\n",
    "\n",
    "g = torch.rand(8, 3)\n",
    "print(\"g\")\n",
    "print(g)\n",
    "\n",
    "h = c.mm(g)\n",
    "print(\"h = c.mm(g)\")\n",
    "print(h)\n",
    "\n",
    "k = c.to_full_tensor().mm(g)\n",
    "print(\"k = c.to_full_tensor().mm(g)\")\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recurrent-ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
